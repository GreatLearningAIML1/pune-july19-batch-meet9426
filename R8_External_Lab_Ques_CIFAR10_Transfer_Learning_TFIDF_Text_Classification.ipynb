{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "R8_External_Lab_Ques_CIFAR10_Transfer_Learning_TFIDF_Text_Classification_Pari.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QGIsF1ADyJ58"
      },
      "source": [
        "# Transfer Learning CIFAR10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E-n6tVFayGBe"
      },
      "source": [
        "* Train a simple convnet on the CIFAR dataset the first 5 output classes [0..4].\n",
        "* Freeze convolutional layers and fine-tune dense layers for the last 5 ouput classes [5..9].\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-HH7_oYwq6Xr",
        "outputId": "71f2d03c-bfac-4ae0-80b8-5d5a24a74857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#importing tensorflow 2 \n",
        "% tensorflow_version 2.x\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iHHNhAVSriC-",
        "colab": {}
      },
      "source": [
        "# Importing neccessary Libraries \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Cq8ejXHJyGYq"
      },
      "source": [
        "### 1. Import CIFAR10 data and create 2 datasets with one dataset having classes from 0 to 4 and other having classes from 5 to 9 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIDsZdUkiXCl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "a2f42b42-94b1-4456-83b1-3988f76e9a85"
      },
      "source": [
        "from keras.datasets import cifar10 "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uWYbxnBayFUP",
        "colab": {}
      },
      "source": [
        "#Load CIFAR10 dataset available within tensorflow\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xTWrfIZay17H",
        "outputId": "f09104e1-2bbe-4c7d-93c7-efcdb411fe24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print ('Shape of x_train :', x_train.shape)\n",
        "print ('Shape of x_test :', x_test.shape)\n",
        "print ('Shape of y_train :', y_train.shape)\n",
        "print ('Shape of y_test :', y_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of x_train : (50000, 32, 32, 3)\n",
            "Shape of x_test : (10000, 32, 32, 3)\n",
            "Shape of y_train : (50000, 1)\n",
            "Shape of y_test : (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb0_r2Ugig3Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "5b4c03dc-852a-4c88-8453-2337cc2e1140"
      },
      "source": [
        "np.unique(y_train)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zdHKUXLjeoI",
        "colab_type": "text"
      },
      "source": [
        "> - y_train and y_test is having total 10 types class that we need to predict.\n",
        "> - We need divide to two category as per problem statement as one dataset having classes from 0 to 4 and other having classes from 5 to 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB3n7BnPkEAe",
        "colab_type": "text"
      },
      "source": [
        "## Creating two different dataset i.e. one dataset having classes from 0 to 4 and other having classes from 5 to 9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyJ1Bwngkp9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_train_4 = np.where(y_train <= 4)\n",
        "index_test_4 = np.where(y_test <= 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzS-GWFilBLW",
        "colab_type": "text"
      },
      "source": [
        "> - selecting all the index position where y_train value is having label <= 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAqXENXGk2VO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_4 = x_train[index_train_4[0]]\n",
        "X_test_4 = x_test[index_test_4[0]]\n",
        "y_train_4 = y_train[index_train_4]\n",
        "y_test_4 = y_test[index_test_4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2UeRvW2lPUS",
        "colab_type": "text"
      },
      "source": [
        "> - With the above selected label we are filtering records from the x_train x_test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BLkfh3Yprgsz",
        "outputId": "3f61157d-e05c-4f56-fad5-760a31308261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(X_train_4.shape)\n",
        "print(X_test_4.shape)\n",
        "print(y_train_4.shape)\n",
        "print(y_test_4.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 32, 32, 3)\n",
            "(5000, 32, 32, 3)\n",
            "(25000,)\n",
            "(5000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g2ChQDwkTOY",
        "colab_type": "text"
      },
      "source": [
        "> - Above dataset(X_train_4 and X_test_4) contains all the records for which label value is less than 5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lg5RtZzSluvo",
        "colab": {}
      },
      "source": [
        "index_train_9 = np.where((y_train >= 5) & (y_train <= 9))\n",
        "index_test_9 = np.where((y_test >= 5) & (y_test <= 9))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xFFPn-ccluwM"
      },
      "source": [
        "> - selecting all the index position where y_train value is having label >= 4 and <=9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BoJayZfeluwN",
        "colab": {}
      },
      "source": [
        "X_train_9 = x_train[index_train_9[0]]\n",
        "X_test_9 = x_test[index_test_9[0]]\n",
        "y_train_9 = y_train[index_train_9]\n",
        "y_test_9 = y_test[index_test_9]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UhXCGu86luwR"
      },
      "source": [
        "> - With the above selected label we are filtering records from the x_train and x_test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3c030a20-a380-4796-92b5-d7e41b3e7bc6",
        "id": "Jh2msa5jluwT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(X_train_9.shape)\n",
        "print(X_test_9.shape)\n",
        "print(y_train_9.shape)\n",
        "print(y_test_9.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 32, 32, 3)\n",
            "(5000, 32, 32, 3)\n",
            "(25000,)\n",
            "(5000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yqpeIzTWluwa"
      },
      "source": [
        "> - Above dataset(X_train_9 and X_test_9) contains all the records for which label value is less than equal 9 and greater than 4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqaZfuxAr4u0",
        "colab_type": "text"
      },
      "source": [
        "### just copying test labels for model evaluation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oLOJnhurkN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test4_to_evaluate = y_test_4\n",
        "y_test9_to_evaluate = y_test_9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xtCKmQh4yXhT"
      },
      "source": [
        "### 2. Use One-hot encoding to divide y_train and y_test into required no of output classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "07apzlzhwFjS",
        "colab": {}
      },
      "source": [
        "# Converting labels to one hot encoding\n",
        "\n",
        "y_train_4 = tf.keras.utils.to_categorical(y_train_4)\n",
        "y_test_4 = tf.keras.utils.to_categorical(y_test_4)\n",
        "y_train_9 = tf.keras.utils.to_categorical(y_train_9,num_classes=10)\n",
        "y_test_9 = tf.keras.utils.to_categorical(y_test_9,num_classes=10)\n",
        "y_train_9 = y_train_9[:,5:10] \n",
        "y_test_9 = y_test_9[:,5:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vhRGkka0wBEm",
        "outputId": "fcfb4cad-8f13-422d-ef2c-b80372d17451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "print(y_train_4.shape)\n",
        "print(y_test_4.shape)\n",
        "print(y_train_9.shape)\n",
        "print(y_test_9.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 5)\n",
            "(5000, 5)\n",
            "(25000, 5)\n",
            "(5000, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uKBpMOM59fR",
        "colab_type": "text"
      },
      "source": [
        "### Visualizing the images in our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6dOiENONbuia",
        "outputId": "fd70b818-1399-4dec-9040-842ad80dcb8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "img = np.random.randint(0, X_test_9.shape[0]) # Get a random integer between 0 and number of examples in test dataset\n",
        "plt.imshow(X_test_9[img],cmap='gray') # Show the image from test dataset"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb6feed5828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndiEyQcEuRCYo2IXIhP8HWtxz76/gEvIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JzyMEe5iLcW",
        "colab_type": "text"
      },
      "source": [
        "## Normalization of our training and test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awtRJtEjiKoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_4 = X_train_4/255 \n",
        "X_test_4 = X_test_4/255\n",
        "X_train_9 = X_train_9/255 \n",
        "X_test_9 = X_test_9/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cuOiKWfeybAl"
      },
      "source": [
        "### 3. Build a sequential neural network model which can classify the classes 0 to 4 of CIFAR10 dataset with at least 80% accuracy on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5HzxNbiiyoBD",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout,Activation\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.metrics import Accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sp5Fcrci82bu",
        "colab": {}
      },
      "source": [
        "#Clear out tensorflow memory\n",
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3koGcHJC9JZL",
        "colab": {}
      },
      "source": [
        "#Initialize model\n",
        "model = Sequential()\n",
        "\n",
        "#normalize data\n",
        "model.add(tf.keras.layers.BatchNormalization(input_shape=X_test_4.shape[1:]))\n",
        "\n",
        "#Add 1'st Conv Layer\n",
        "model.add(Conv2D(32, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "\n",
        "#Add 2'nd Conv Layer\n",
        "model.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "#Add 1'st Max Pool layer\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#Add 1'st dropout layer\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Batcth normalizing\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "#Add 3'rd Conv Layer\n",
        "model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "\n",
        "#Add 4'th Conv Layer\n",
        "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
        "\n",
        "#Add 2'nd Max Pool layer\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "#Add 2'nd dropout layer\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Flattening the layer \n",
        "model.add(Flatten())\n",
        "\n",
        "# Dense layer \n",
        "model.add(Dense(512,activation ='relu'))\n",
        "\n",
        "# Output layer \n",
        "model.add(Dense(5,activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PepurIEz9pVV",
        "colab": {}
      },
      "source": [
        "#Specify Loass and Optimizer\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XVaP9zm89y73",
        "outputId": "be82f79f-69dd-46c3-fd61-d871ef2e51e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 32, 32, 3)         12        \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 15, 15, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 2565      \n",
            "=================================================================\n",
            "Total params: 1,248,433\n",
            "Trainable params: 1,248,363\n",
            "Non-trainable params: 70\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o_VCDB3Byb1a",
        "colab": {}
      },
      "source": [
        "# CallBacks \n",
        "chkpt = tf.keras.callbacks.ModelCheckpoint('./cifar.h5', \n",
        "                                           monitor='val_acc', save_best_only=True,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N35LbYAwdd2Y",
        "colab_type": "text"
      },
      "source": [
        "> - Saving the best model using checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jk5pz3FOJ99y",
        "outputId": "5d07ead4-389a-48a2-d11e-aafbe71cd0f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(X_train_4,y_train_4,          \n",
        "          validation_data=(X_test_4,y_test_4),\n",
        "          epochs=30,\n",
        "          batch_size=32, callbacks=[chkpt],workers=4)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "24768/25000 [============================>.] - ETA: 0s - loss: 1.0036 - accuracy: 0.5917WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 7s 280us/sample - loss: 1.0022 - accuracy: 0.5922 - val_loss: 0.8050 - val_accuracy: 0.6664\n",
            "Epoch 2/30\n",
            "24800/25000 [============================>.] - ETA: 0s - loss: 0.7442 - accuracy: 0.7097WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 187us/sample - loss: 0.7442 - accuracy: 0.7096 - val_loss: 0.6657 - val_accuracy: 0.7408\n",
            "Epoch 3/30\n",
            "24736/25000 [============================>.] - ETA: 0s - loss: 0.6379 - accuracy: 0.7586WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 184us/sample - loss: 0.6378 - accuracy: 0.7589 - val_loss: 0.5967 - val_accuracy: 0.7736\n",
            "Epoch 4/30\n",
            "24928/25000 [============================>.] - ETA: 0s - loss: 0.5624 - accuracy: 0.7899WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 186us/sample - loss: 0.5617 - accuracy: 0.7902 - val_loss: 0.5764 - val_accuracy: 0.7864\n",
            "Epoch 5/30\n",
            "24832/25000 [============================>.] - ETA: 0s - loss: 0.4961 - accuracy: 0.8136WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 186us/sample - loss: 0.4962 - accuracy: 0.8137 - val_loss: 0.5689 - val_accuracy: 0.7800\n",
            "Epoch 6/30\n",
            "24864/25000 [============================>.] - ETA: 0s - loss: 0.4570 - accuracy: 0.8298WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 186us/sample - loss: 0.4568 - accuracy: 0.8300 - val_loss: 0.4963 - val_accuracy: 0.8202\n",
            "Epoch 7/30\n",
            "24992/25000 [============================>.] - ETA: 0s - loss: 0.4189 - accuracy: 0.8454WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 185us/sample - loss: 0.4188 - accuracy: 0.8454 - val_loss: 0.4882 - val_accuracy: 0.8240\n",
            "Epoch 8/30\n",
            "24960/25000 [============================>.] - ETA: 0s - loss: 0.3873 - accuracy: 0.8553WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 187us/sample - loss: 0.3869 - accuracy: 0.8555 - val_loss: 0.4644 - val_accuracy: 0.8320\n",
            "Epoch 9/30\n",
            "24800/25000 [============================>.] - ETA: 0s - loss: 0.3532 - accuracy: 0.8679WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 187us/sample - loss: 0.3532 - accuracy: 0.8678 - val_loss: 0.5426 - val_accuracy: 0.8148\n",
            "Epoch 10/30\n",
            "24704/25000 [============================>.] - ETA: 0s - loss: 0.3177 - accuracy: 0.8837WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 187us/sample - loss: 0.3178 - accuracy: 0.8835 - val_loss: 0.4696 - val_accuracy: 0.8310\n",
            "Epoch 11/30\n",
            "24896/25000 [============================>.] - ETA: 0s - loss: 0.3006 - accuracy: 0.8883WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 186us/sample - loss: 0.3006 - accuracy: 0.8882 - val_loss: 0.5152 - val_accuracy: 0.8216\n",
            "Epoch 12/30\n",
            "24992/25000 [============================>.] - ETA: 0s - loss: 0.2813 - accuracy: 0.8973WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 185us/sample - loss: 0.2813 - accuracy: 0.8973 - val_loss: 0.4770 - val_accuracy: 0.8364\n",
            "Epoch 13/30\n",
            "24736/25000 [============================>.] - ETA: 0s - loss: 0.2544 - accuracy: 0.9068WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 186us/sample - loss: 0.2542 - accuracy: 0.9070 - val_loss: 0.5112 - val_accuracy: 0.8280\n",
            "Epoch 14/30\n",
            "24768/25000 [============================>.] - ETA: 0s - loss: 0.2296 - accuracy: 0.9182WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 186us/sample - loss: 0.2302 - accuracy: 0.9180 - val_loss: 0.5443 - val_accuracy: 0.8266\n",
            "Epoch 15/30\n",
            "24928/25000 [============================>.] - ETA: 0s - loss: 0.2157 - accuracy: 0.9229WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 185us/sample - loss: 0.2160 - accuracy: 0.9228 - val_loss: 0.5507 - val_accuracy: 0.8244\n",
            "Epoch 16/30\n",
            "24928/25000 [============================>.] - ETA: 0s - loss: 0.2070 - accuracy: 0.9274WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 184us/sample - loss: 0.2076 - accuracy: 0.9272 - val_loss: 0.5842 - val_accuracy: 0.8220\n",
            "Epoch 17/30\n",
            "24896/25000 [============================>.] - ETA: 0s - loss: 0.1905 - accuracy: 0.9330WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 186us/sample - loss: 0.1902 - accuracy: 0.9331 - val_loss: 0.5672 - val_accuracy: 0.8318\n",
            "Epoch 18/30\n",
            "24704/25000 [============================>.] - ETA: 0s - loss: 0.1842 - accuracy: 0.9338WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 186us/sample - loss: 0.1843 - accuracy: 0.9340 - val_loss: 0.6045 - val_accuracy: 0.8226\n",
            "Epoch 19/30\n",
            "24800/25000 [============================>.] - ETA: 0s - loss: 0.1722 - accuracy: 0.9402WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 186us/sample - loss: 0.1719 - accuracy: 0.9403 - val_loss: 0.6003 - val_accuracy: 0.8272\n",
            "Epoch 20/30\n",
            "24736/25000 [============================>.] - ETA: 0s - loss: 0.1547 - accuracy: 0.9457WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 186us/sample - loss: 0.1547 - accuracy: 0.9456 - val_loss: 0.5922 - val_accuracy: 0.8274\n",
            "Epoch 21/30\n",
            "24736/25000 [============================>.] - ETA: 0s - loss: 0.1512 - accuracy: 0.9471WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 187us/sample - loss: 0.1513 - accuracy: 0.9470 - val_loss: 0.6261 - val_accuracy: 0.8296\n",
            "Epoch 22/30\n",
            "24704/25000 [============================>.] - ETA: 0s - loss: 0.1369 - accuracy: 0.9497WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 187us/sample - loss: 0.1371 - accuracy: 0.9497 - val_loss: 0.6565 - val_accuracy: 0.8294\n",
            "Epoch 23/30\n",
            "24992/25000 [============================>.] - ETA: 0s - loss: 0.1345 - accuracy: 0.9525WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 190us/sample - loss: 0.1346 - accuracy: 0.9525 - val_loss: 0.6369 - val_accuracy: 0.8344\n",
            "Epoch 24/30\n",
            "24928/25000 [============================>.] - ETA: 0s - loss: 0.1300 - accuracy: 0.9564WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 200us/sample - loss: 0.1301 - accuracy: 0.9562 - val_loss: 0.6462 - val_accuracy: 0.8382\n",
            "Epoch 25/30\n",
            "24736/25000 [============================>.] - ETA: 0s - loss: 0.1214 - accuracy: 0.9593WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 197us/sample - loss: 0.1220 - accuracy: 0.9591 - val_loss: 0.6353 - val_accuracy: 0.8462\n",
            "Epoch 26/30\n",
            "24896/25000 [============================>.] - ETA: 0s - loss: 0.1206 - accuracy: 0.9594WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 185us/sample - loss: 0.1204 - accuracy: 0.9595 - val_loss: 0.6918 - val_accuracy: 0.8250\n",
            "Epoch 27/30\n",
            "24736/25000 [============================>.] - ETA: 0s - loss: 0.1132 - accuracy: 0.9620WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 188us/sample - loss: 0.1132 - accuracy: 0.9620 - val_loss: 0.6667 - val_accuracy: 0.8294\n",
            "Epoch 28/30\n",
            "24928/25000 [============================>.] - ETA: 0s - loss: 0.1127 - accuracy: 0.9626WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 186us/sample - loss: 0.1125 - accuracy: 0.9626 - val_loss: 0.6991 - val_accuracy: 0.8218\n",
            "Epoch 29/30\n",
            "24704/25000 [============================>.] - ETA: 0s - loss: 0.1042 - accuracy: 0.9646WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 184us/sample - loss: 0.1043 - accuracy: 0.9646 - val_loss: 0.7131 - val_accuracy: 0.8338\n",
            "Epoch 30/30\n",
            "24832/25000 [============================>.] - ETA: 0s - loss: 0.1154 - accuracy: 0.9621WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 5s 185us/sample - loss: 0.1150 - accuracy: 0.9622 - val_loss: 0.6687 - val_accuracy: 0.8400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2y-dPJDbkVZ6",
        "colab": {}
      },
      "source": [
        "model.save_weights('weight.hdf5') # to save weights of our model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ns5dsD9eixE",
        "colab_type": "text"
      },
      "source": [
        "> - Weight of the best model is saved as `'weight.hdf5'` file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iyswCJUb7hAE",
        "colab": {}
      },
      "source": [
        "model.save('model.hdf5') # to save our model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIhR8M7De0zo",
        "colab_type": "text"
      },
      "source": [
        "> - Best model is saved as `'model.hdf5'` file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnnaUPEye8Fq",
        "colab_type": "text"
      },
      "source": [
        "### Visualizing model performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xs-ChP9wT9Yv",
        "outputId": "eb8ae082-aae7-438e-8f52-e3747f80c45b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val_acc'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEWCAYAAACT7WsrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njDHGNMqShDHGmEZZkjDGGNOo/wcKhUyNKwdT+gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "229ZI0MFpE-o",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating the above Model performance. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYrDvPQNpEOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predicting on test data \n",
        "y_pred1 = model.predict_classes(X_test_4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UIkzkEipnuZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "3ea90270-94d5-42bf-9e1b-02aaf93ec735"
      },
      "source": [
        "# calculate accuracy of class predictions\n",
        "from sklearn import metrics\n",
        "metrics.accuracy_score(y_test4_to_evaluate, y_pred1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.84"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-cOjrodraG2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "f50cbc1e-56c0-48f4-8b9a-9cb3f6460045"
      },
      "source": [
        "# Classification report  CNN model\n",
        "print(metrics.classification_report(y_test4_to_evaluate, y_pred1))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.88      1000\n",
            "           1       0.95      0.96      0.95      1000\n",
            "           2       0.74      0.79      0.76      1000\n",
            "           3       0.79      0.77      0.78      1000\n",
            "           4       0.85      0.81      0.83      1000\n",
            "\n",
            "    accuracy                           0.84      5000\n",
            "   macro avg       0.84      0.84      0.84      5000\n",
            "weighted avg       0.84      0.84      0.84      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1-uUPqWpyeyX"
      },
      "source": [
        "### 4. In the model which was built above (for classification of classes 0-4 in CIFAR10), make only the dense layers to be trainable and conv layers to be non-trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "szHjJgDvyfCt",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UC7RjWx_zxdj",
        "colab": {}
      },
      "source": [
        "# Loading the model \n",
        "model2 =  load_model('model.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSZZqKx9fnYD",
        "colab_type": "text"
      },
      "source": [
        "> - Model created for classes 0-4 is loaded to use on for predicting the 0-5 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2LVE_nFEwH0N",
        "outputId": "96422999-4a8f-4a93-adb2-d939cfe375f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        }
      },
      "source": [
        "#Freezing layers in the model which don't have 'dense' in their name\n",
        "\n",
        "for layer in model2.layers[:13]:\n",
        "  if('dense' not in layer.name):                                                #prefix detection to freeze layers which does not have dense\n",
        "    #Freezing a layer\n",
        "    layer.trainable = False\n",
        "\n",
        "#Module to print colourful statements\n",
        "from termcolor import colored\n",
        "\n",
        "#Check which layers have been frozen \n",
        "for layer in model2.layers:\n",
        "  print (colored(layer.name, 'blue'))\n",
        "  print (colored(layer.trainable, 'red'))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[34mbatch_normalization\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mconv2d\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mconv2d_1\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mmax_pooling2d\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mdropout\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mbatch_normalization_1\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mconv2d_2\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mconv2d_3\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mmax_pooling2d_1\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mdropout_1\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mflatten\u001b[0m\n",
            "\u001b[31mFalse\u001b[0m\n",
            "\u001b[34mdense\u001b[0m\n",
            "\u001b[31mTrue\u001b[0m\n",
            "\u001b[34mdense_1\u001b[0m\n",
            "\u001b[31mTrue\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "944xfvfZogdA",
        "colab": {}
      },
      "source": [
        "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqf2k8K8gHis",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "outputId": "bf6d4983-9e37-421b-ffee-9976262cdac7"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (None, 32, 32, 3)         12        \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 15, 15, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 2565      \n",
            "=================================================================\n",
            "Total params: 1,248,433\n",
            "Trainable params: 1,182,725\n",
            "Non-trainable params: 65,708\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sn4BXSS7es9U"
      },
      "source": [
        "### 5. Utilize the the model trained on CIFAR 10 (classes 0 to 4) to classify the classes 5 to 9 of CIFAR 10 (Use Transfer Learning)\n",
        "\n",
        "Achieve an accuracy of more than 85% on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1_EJP3sDqs6v",
        "colab": {}
      },
      "source": [
        "chkpt1 = tf.keras.callbacks.ModelCheckpoint('./cifar1.h5', \n",
        "                                           monitor='val_acc', save_best_only=True,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dcHeHCHuAS0M",
        "outputId": "7a45731e-bb76-4c49-e9ad-b9707d673f22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history2 = model2.fit(X_train_9,y_train_9,          \n",
        "          validation_data=(X_test_9,y_test_9),\n",
        "          epochs=30,\n",
        "          batch_size=32, callbacks=[chkpt1],workers=4)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "24640/25000 [============================>.] - ETA: 0s - loss: 1.1539 - accuracy: 0.6900WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 175us/sample - loss: 1.1451 - accuracy: 0.6914 - val_loss: 0.5210 - val_accuracy: 0.8108\n",
            "Epoch 2/30\n",
            "24960/25000 [============================>.] - ETA: 0s - loss: 0.4925 - accuracy: 0.8238WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 149us/sample - loss: 0.4922 - accuracy: 0.8238 - val_loss: 0.4481 - val_accuracy: 0.8364\n",
            "Epoch 3/30\n",
            "24928/25000 [============================>.] - ETA: 0s - loss: 0.3991 - accuracy: 0.8587WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 149us/sample - loss: 0.3989 - accuracy: 0.8589 - val_loss: 0.4064 - val_accuracy: 0.8530\n",
            "Epoch 4/30\n",
            "24608/25000 [============================>.] - ETA: 0s - loss: 0.3362 - accuracy: 0.8788WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 150us/sample - loss: 0.3359 - accuracy: 0.8790 - val_loss: 0.3954 - val_accuracy: 0.8592\n",
            "Epoch 5/30\n",
            "24704/25000 [============================>.] - ETA: 0s - loss: 0.2860 - accuracy: 0.8941WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 150us/sample - loss: 0.2869 - accuracy: 0.8937 - val_loss: 0.3839 - val_accuracy: 0.8630\n",
            "Epoch 6/30\n",
            "24736/25000 [============================>.] - ETA: 0s - loss: 0.2390 - accuracy: 0.9139WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 152us/sample - loss: 0.2393 - accuracy: 0.9139 - val_loss: 0.4016 - val_accuracy: 0.8650\n",
            "Epoch 7/30\n",
            "24896/25000 [============================>.] - ETA: 0s - loss: 0.2066 - accuracy: 0.9253WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 150us/sample - loss: 0.2065 - accuracy: 0.9253 - val_loss: 0.4016 - val_accuracy: 0.8650\n",
            "Epoch 8/30\n",
            "24640/25000 [============================>.] - ETA: 0s - loss: 0.1788 - accuracy: 0.9361WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 150us/sample - loss: 0.1786 - accuracy: 0.9361 - val_loss: 0.4326 - val_accuracy: 0.8670\n",
            "Epoch 9/30\n",
            "24992/25000 [============================>.] - ETA: 0s - loss: 0.1512 - accuracy: 0.9468WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 149us/sample - loss: 0.1511 - accuracy: 0.9468 - val_loss: 0.4233 - val_accuracy: 0.8702\n",
            "Epoch 10/30\n",
            "24704/25000 [============================>.] - ETA: 0s - loss: 0.1361 - accuracy: 0.9524WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 147us/sample - loss: 0.1362 - accuracy: 0.9524 - val_loss: 0.4343 - val_accuracy: 0.8748\n",
            "Epoch 11/30\n",
            "24736/25000 [============================>.] - ETA: 0s - loss: 0.1208 - accuracy: 0.9565WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 147us/sample - loss: 0.1210 - accuracy: 0.9564 - val_loss: 0.4410 - val_accuracy: 0.8724\n",
            "Epoch 12/30\n",
            "24704/25000 [============================>.] - ETA: 0s - loss: 0.1018 - accuracy: 0.9638WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 149us/sample - loss: 0.1027 - accuracy: 0.9635 - val_loss: 0.4801 - val_accuracy: 0.8716\n",
            "Epoch 13/30\n",
            "24736/25000 [============================>.] - ETA: 0s - loss: 0.0964 - accuracy: 0.9665WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 148us/sample - loss: 0.0966 - accuracy: 0.9665 - val_loss: 0.4725 - val_accuracy: 0.8704\n",
            "Epoch 14/30\n",
            "24928/25000 [============================>.] - ETA: 0s - loss: 0.0908 - accuracy: 0.9688WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 149us/sample - loss: 0.0908 - accuracy: 0.9688 - val_loss: 0.4921 - val_accuracy: 0.8726\n",
            "Epoch 15/30\n",
            "24864/25000 [============================>.] - ETA: 0s - loss: 0.0787 - accuracy: 0.9716WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 148us/sample - loss: 0.0784 - accuracy: 0.9718 - val_loss: 0.4974 - val_accuracy: 0.8798\n",
            "Epoch 16/30\n",
            "24608/25000 [============================>.] - ETA: 0s - loss: 0.0800 - accuracy: 0.9717WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 149us/sample - loss: 0.0800 - accuracy: 0.9716 - val_loss: 0.5071 - val_accuracy: 0.8806\n",
            "Epoch 17/30\n",
            "24960/25000 [============================>.] - ETA: 0s - loss: 0.0759 - accuracy: 0.9731WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 149us/sample - loss: 0.0759 - accuracy: 0.9731 - val_loss: 0.5179 - val_accuracy: 0.8790\n",
            "Epoch 18/30\n",
            "24928/25000 [============================>.] - ETA: 0s - loss: 0.0695 - accuracy: 0.9772WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 149us/sample - loss: 0.0695 - accuracy: 0.9772 - val_loss: 0.5131 - val_accuracy: 0.8764\n",
            "Epoch 19/30\n",
            "24864/25000 [============================>.] - ETA: 0s - loss: 0.0637 - accuracy: 0.9779WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 147us/sample - loss: 0.0638 - accuracy: 0.9778 - val_loss: 0.5232 - val_accuracy: 0.8810\n",
            "Epoch 20/30\n",
            "24864/25000 [============================>.] - ETA: 0s - loss: 0.0608 - accuracy: 0.9798WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 150us/sample - loss: 0.0611 - accuracy: 0.9798 - val_loss: 0.5378 - val_accuracy: 0.8802\n",
            "Epoch 21/30\n",
            "24768/25000 [============================>.] - ETA: 0s - loss: 0.0602 - accuracy: 0.9809WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 150us/sample - loss: 0.0601 - accuracy: 0.9810 - val_loss: 0.5447 - val_accuracy: 0.8772\n",
            "Epoch 22/30\n",
            "24928/25000 [============================>.] - ETA: 0s - loss: 0.0621 - accuracy: 0.9791WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 151us/sample - loss: 0.0620 - accuracy: 0.9791 - val_loss: 0.5452 - val_accuracy: 0.8772\n",
            "Epoch 23/30\n",
            "24864/25000 [============================>.] - ETA: 0s - loss: 0.0584 - accuracy: 0.9817WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 148us/sample - loss: 0.0585 - accuracy: 0.9817 - val_loss: 0.5725 - val_accuracy: 0.8734\n",
            "Epoch 24/30\n",
            "24864/25000 [============================>.] - ETA: 0s - loss: 0.0583 - accuracy: 0.9805WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 150us/sample - loss: 0.0582 - accuracy: 0.9806 - val_loss: 0.5624 - val_accuracy: 0.8748\n",
            "Epoch 25/30\n",
            "24992/25000 [============================>.] - ETA: 0s - loss: 0.0584 - accuracy: 0.9814WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 149us/sample - loss: 0.0584 - accuracy: 0.9814 - val_loss: 0.5860 - val_accuracy: 0.8690\n",
            "Epoch 26/30\n",
            "24768/25000 [============================>.] - ETA: 0s - loss: 0.0508 - accuracy: 0.9830WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 147us/sample - loss: 0.0511 - accuracy: 0.9830 - val_loss: 0.5707 - val_accuracy: 0.8752\n",
            "Epoch 27/30\n",
            "24960/25000 [============================>.] - ETA: 0s - loss: 0.0451 - accuracy: 0.9845WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 150us/sample - loss: 0.0454 - accuracy: 0.9844 - val_loss: 0.5806 - val_accuracy: 0.8804\n",
            "Epoch 28/30\n",
            "24864/25000 [============================>.] - ETA: 0s - loss: 0.0508 - accuracy: 0.9847WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 147us/sample - loss: 0.0506 - accuracy: 0.9848 - val_loss: 0.6093 - val_accuracy: 0.8808\n",
            "Epoch 29/30\n",
            "24896/25000 [============================>.] - ETA: 0s - loss: 0.0502 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 149us/sample - loss: 0.0501 - accuracy: 0.9833 - val_loss: 0.6060 - val_accuracy: 0.8824\n",
            "Epoch 30/30\n",
            "24896/25000 [============================>.] - ETA: 0s - loss: 0.0434 - accuracy: 0.9856WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "25000/25000 [==============================] - 4s 149us/sample - loss: 0.0436 - accuracy: 0.9856 - val_loss: 0.6190 - val_accuracy: 0.8756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1ziOQMRGbLTn",
        "outputId": "54acba84-6f8b-4867-d141-407f53551097",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history2.history['accuracy'])\n",
        "plt.plot(history2.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val_acc'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEWCAYAAACT7WsrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0zDuRecXzEtr"
      },
      "source": [
        "# Text classification using TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xMPlEJhHzb6P"
      },
      "source": [
        "### 6. Load the dataset from sklearn.datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Fe-B59u3zHNb",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PRrMemVQzbHU",
        "colab": {}
      },
      "source": [
        "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-sZX0UbJzmg5"
      },
      "source": [
        "### 7. Training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CITr_5aXziJ2",
        "colab": {}
      },
      "source": [
        "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xcESc5QXzr6p"
      },
      "source": [
        "### 8. Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ysInblUMzpvl",
        "colab": {}
      },
      "source": [
        "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DriL2yZ50DQq"
      },
      "source": [
        "###  a.  You can access the values for the target variable using .target attribute \n",
        "###  b. You can access the name of the class in the target variable with .target_names\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vlUuai99z1hX",
        "outputId": "8874ecad-ea8b-4d26-8cfb-861fa8fa7ee8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "twenty_train.target"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 3, ..., 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VEKzaDfSz5E-",
        "outputId": "9e65b7af-8591-4659-aeff-1af62e198611",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "twenty_train.target_names"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "clBMKHzC0_N1",
        "outputId": "57392b9c-880c-49a0-92f8-cf65b7646f43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "twenty_train.data[0:5]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['From: sd345@city.ac.uk (Michael Collier)\\nSubject: Converting images to HP LaserJet III?\\nNntp-Posting-Host: hampton\\nOrganization: The City University\\nLines: 14\\n\\nDoes anyone know of a good way (standard PC application/PD utility) to\\nconvert tif/img/tga files into LaserJet III format.  We would also like to\\ndo the same, converting to HPGL (HP plotter) files.\\n\\nPlease email any response.\\n\\nIs this the correct group?\\n\\nThanks in advance.  Michael.\\n-- \\nMichael Collier (Programmer)                 The Computer Unit,\\nEmail: M.P.Collier@uk.ac.city                The City University,\\nTel: 071 477-8000 x3769                      London,\\nFax: 071 477-8565                            EC1V 0HB.\\n',\n",
              " \"From: ani@ms.uky.edu (Aniruddha B. Deglurkar)\\nSubject: help: Splitting a trimming region along a mesh \\nOrganization: University Of Kentucky, Dept. of Math Sciences\\nLines: 28\\n\\n\\n\\n\\tHi,\\n\\n\\tI have a problem, I hope some of the 'gurus' can help me solve.\\n\\n\\tBackground of the problem:\\n\\tI have a rectangular mesh in the uv domain, i.e  the mesh is a \\n\\tmapping of a 3d Bezier patch into 2d. The area in this domain\\n\\twhich is inside a trimming loop had to be rendered. The trimming\\n\\tloop is a set of 2d Bezier curve segments.\\n\\tFor the sake of notation: the mesh is made up of cells.\\n\\n\\tMy problem is this :\\n\\tThe trimming area has to be split up into individual smaller\\n\\tcells bounded by the trimming curve segments. If a cell\\n\\tis wholly inside the area...then it is output as a whole ,\\n\\telse it is trivially rejected. \\n\\n\\tDoes any body know how thiss can be done, or is there any algo. \\n\\tsomewhere for doing this.\\n\\n\\tAny help would be appreciated.\\n\\n\\tThanks, \\n\\tAni.\\n-- \\nTo get irritated is human, to stay cool, divine.\\n\",\n",
              " \"From: djohnson@cs.ucsd.edu (Darin Johnson)\\nSubject: Re: harrassed at work, could use some prayers\\nOrganization: =CSE Dept., U.C. San Diego\\nLines: 63\\n\\n(Well, I'll email also, but this may apply to other people, so\\nI'll post also.)\\n\\n>I've been working at this company for eight years in various\\n>engineering jobs.  I'm female.  Yesterday I counted and realized that\\n>on seven different occasions I've been sexually harrassed at this\\n>company.\\n\\n>I dreaded coming back to work today.  What if my boss comes in to ask\\n>me some kind of question...\\n\\nYour boss should be the person bring these problems to.  If he/she\\ndoes not seem to take any action, keep going up higher and higher.\\nSexual harrassment does not need to be tolerated, and it can be an\\nenormous emotional support to discuss this with someone and know that\\nthey are trying to do something about it.  If you feel you can not\\ndiscuss this with your boss, perhaps your company has a personnel\\ndepartment that can work for you while preserving your privacy.  Most\\ncompanies will want to deal with this problem because constant anxiety\\ndoes seriously affect how effectively employees do their jobs.\\n\\nIt is unclear from your letter if you have done this or not.  It is\\nnot inconceivable that management remains ignorant of employee\\nproblems/strife even after eight years (it's a miracle if they do\\nnotice).  Perhaps your manager did not bring to the attention of\\nhigher ups?  If the company indeed does seem to want to ignore the\\nentire problem, there may be a state agency willing to fight with\\nyou.  (check with a lawyer, a women's resource center, etc to find out)\\n\\nYou may also want to discuss this with your paster, priest, husband,\\netc.  That is, someone you know will not be judgemental and that is\\nsupportive, comforting, etc.  This will bring a lot of healing.\\n\\n>So I returned at 11:25, only to find that ever single\\n>person had already left for lunch.  They left at 11:15 or so.  No one\\n>could be bothered to call me at the other building, even though my\\n>number was posted.\\n\\nThis happens to a lot of people.  Honest.  I believe it may seem\\nto be due to gross insensitivity because of the feelings you are\\ngoing through.  People in offices tend to be more insensitive while\\nworking than they normally are (maybe it's the hustle or stress or...)\\nI've had this happen to me a lot, often because they didn't realize\\nmy car was broken, etc.  Then they will come back and wonder why I\\ndidn't want to go (this would tend to make me stop being angry at\\nbeing ignored and make me laugh).  Once, we went off without our\\nboss, who was paying for the lunch :-)\\n\\n>For this\\n>reason I hope good Mr. Moderator allows me this latest indulgence.\\n\\nWell, if you can't turn to the computer for support, what would\\nwe do?  (signs of the computer age :-)\\n\\nIn closing, please don't let the hateful actions of a single person\\nharm you.  They are doing it because they are still the playground\\nbully and enjoy seeing the hurt they cause.  And you should not\\naccept the opinions of an imbecile that you are worthless - much\\nwiser people hold you in great esteem.\\n-- \\nDarin Johnson\\ndjohnson@ucsd.edu\\n  - Luxury!  In MY day, we had to make do with 5 bytes of swap...\\n\",\n",
              " 'From: s0612596@let.rug.nl (M.M. Zwart)\\nSubject: catholic church poland\\nOrganization: Faculteit der Letteren, Rijksuniversiteit Groningen, NL\\nLines: 10\\n\\nHello,\\n\\nI\\'m writing a paper on the role of the catholic church in Poland after 1989. \\nCan anyone tell me more about this, or fill me in on recent books/articles(\\nin english, german or french). Most important for me is the role of the \\nchurch concerning the abortion-law, religious education at schools,\\nbirth-control and the relation church-state(government). Thanx,\\n\\n                                                 Masja,\\n\"M.M.Zwart\"<s0612596@let.rug.nl>\\n',\n",
              " 'From: stanly@grok11.columbiasc.ncr.com (stanly)\\nSubject: Re: Elder Brother\\nOrganization: NCR Corp., Columbia SC\\nLines: 15\\n\\nIn article <Apr.8.00.57.41.1993.28246@athos.rutgers.edu> REXLEX@fnal.gov writes:\\n>In article <Apr.7.01.56.56.1993.22824@athos.rutgers.edu> shrum@hpfcso.fc.hp.com\\n>Matt. 22:9-14 \\'Go therefore to the main highways, and as many as you find\\n>there, invite to the wedding feast.\\'...\\n\\n>hmmmmmm.  Sounds like your theology and Christ\\'s are at odds. Which one am I \\n>to believe?\\n\\nIn this parable, Jesus tells the parable of the wedding feast. \"The kingdom\\nof heaven is like unto a certain king which made a marriage for his son\".\\nSo the wedding clothes were customary,  and \"given\" to those who \"chose\" to\\nattend.  This man \"refused\" to wear the clothes.  The wedding clothes are\\nequalivant to the \"clothes of righteousness\".  When Jesus died for our sins,\\nthose \"clothes\" were then provided.  Like that man, it is our decision to\\nput the clothes on.\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hTz4EaN_1WGc"
      },
      "source": [
        "### 9.  Now with dependent and independent data available for both train and test datasets, using TfidfVectorizer fit and transform the training data and test data and get the tfidf features for both"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "srxDOlBBTPCH",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1LFWNRM3XxAA",
        "colab": {}
      },
      "source": [
        "y_trn = twenty_train.target\n",
        "y_tst = twenty_test.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H5G477f81C0Z",
        "outputId": "db4700bc-eb58-47ec-9c3b-f4fbcb8a9879",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "vect = TfidfVectorizer()\n",
        "# create a document-term matrix using TF-IDF\n",
        "vect = TfidfVectorizer(stop_words='english')\n",
        "dtm_train = vect.fit_transform(twenty_train.data)\n",
        "dtm_test = vect.transform(twenty_test.data)\n",
        "features = vect.get_feature_names()\n",
        "print (dtm_train.shape)\n",
        "print (dtm_test.shape)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2257, 35482)\n",
            "(1502, 35482)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tp_fDINJ1t4L"
      },
      "source": [
        "### 10. Use logisticRegression with tfidf features as input and targets as output and train the model and report the train and test accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "THlN2b5d1yQp",
        "outputId": "d96c8417-5993-460f-bca4-92b87e89a5f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# use logistic regression with text column only\n",
        "logreg = LogisticRegression(C=1e9)\n",
        "logreg.fit(dtm_train, y_trn)\n",
        "y_pred_class = logreg.predict(dtm_test)\n",
        "print('test Accuracy ',metrics.accuracy_score(y_tst, y_pred_class))\n",
        "y_pred_class_train = logreg.predict(dtm_train)\n",
        "print('train accuracy ',metrics.accuracy_score(y_trn, y_pred_class_train))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test Accuracy  0.9174434087882823\n",
            "train accuracy  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L4fHevd6YTy1",
        "outputId": "60b7147c-017b-45d0-e557-494434de4c03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "# Classification report  \n",
        "print(metrics.classification_report(y_tst, y_pred_class))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.85      0.86       319\n",
            "           1       0.95      0.94      0.95       389\n",
            "           2       0.93      0.93      0.93       396\n",
            "           3       0.90      0.94      0.92       398\n",
            "\n",
            "    accuracy                           0.92      1502\n",
            "   macro avg       0.92      0.91      0.91      1502\n",
            "weighted avg       0.92      0.92      0.92      1502\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}